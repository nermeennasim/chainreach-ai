# ğŸ¯ Customer Segmentation Agent (Person 1)

**AI-Powered Customer Classification using RFM Analysis & K-Means Clustering**

Port: **5001**

---

## ğŸ“‹ Overview

The Segmentation Agent analyzes customer transaction data to classify users into meaningful behavioral segments. It uses **RFM (Recency, Frequency, Monetary)** analysis combined with **K-Means clustering** to identify 5 distinct customer groups.

### What it does:
- âœ… Loads and cleans customer transaction data
- âœ… Builds RFM features for each customer
- âœ… Trains K-Means clustering model
- âœ… Generates segment profiles with statistics
- âœ… Provides REST API for real-time segment prediction

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Raw Transaction Data            â”‚
â”‚  (Online Retail.xlsx)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  train.py    â”‚  Data Loading
        â”‚  â€¢ Load      â”‚  & Cleaning
        â”‚  â€¢ Clean     â”‚
        â”‚  â€¢ RFM       â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  train.py    â”‚  Model Training
        â”‚  â€¢ Scale     â”‚
        â”‚  â€¢ K-Means   â”‚  K=5 Clusters
        â”‚  â€¢ Profiles  â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ARTIFACTS  â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ kmeans_model â”‚
        â”‚ scaler       â”‚
        â”‚ profiles.jsonâ”‚
        â”‚ rfm_table    â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   app.py     â”‚  REST API
        â”‚  â€¢ /health   â”‚  Flask
        â”‚  â€¢ /segment/ â”‚
        â”‚     manual   â”‚  Port 5001
        â”‚  â€¢ /segment/ â”‚
        â”‚     customer â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Environment Variables & Configuration

All configuration is defined at the top of each Python file:

### `train_segmentation.py`
```python
DATA_PATH = "data/Online Retail.xlsx"      # Input transaction data
MODEL_PATH = "models/kmeans_model.pkl"     # Output: Trained model
SCALER_PATH = "models/scaler.pkl"          # Output: Feature scaler
PROFILES_PATH = "models/segment_profiles.json"  # Output: Segment stats
RFM_PATH = "models/rfm_table.csv"         # Output: RFM features

N_CLUSTERS = 5              # Number of customer segments
RANDOM_STATE = 42           # Reproducibility seed
N_INIT = 10                 # K-Means initializations
```

### `app.py`
```python
MODEL_PATH = "models/kmeans_model.pkl"
SCALER_PATH = "models/scaler.pkl"
PROFILES_PATH = "models/segment_profiles.json"
RFM_PATH = "models/rfm_table.csv"
```

**Note:** To use environment variables instead of hard-coded paths:
```python
import os
MODEL_PATH = os.getenv("MODEL_PATH", "models/kmeans_model.pkl")
```

---

## ğŸ“¦ Dependencies

### Python Version
- **Python 3.10+**

### Required Packages
See `requirements.txt`:
```
Flask==3.0.0           # REST API framework
pandas==2.2.0          # Data manipulation
numpy==1.26.0          # Numerical computing
scikit-learn==1.4.0    # ML algorithms
joblib==1.3.2          # Model serialization
openpyxl==3.1.2        # Excel file reading
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
cd segmentation_agent
pip install -r requirements.txt
```

### 2. Train the Model
```bash
python train_segmentation.py
```

**Output:**
- âœ… `models/kmeans_model.pkl` - Trained K-Means model
- âœ… `models/scaler.pkl` - StandardScaler
- âœ… `models/segment_profiles.json` - Segment statistics
- âœ… `models/rfm_table.csv` - Customer RFM features

### 3. Start the API Server
```bash
python app.py
```

**Output:**
```
 * Serving Flask app 'app'
 * Running on http://127.0.0.1:5001
```

### 4. Test the Endpoints

#### Health Check
```bash
curl http://localhost:5001/health
```

Response:
```json
{"status": "ok", "service": "segmentation-agent"}
```

#### Predict Segment (Manual Input)
```bash
curl -X POST http://localhost:5001/segment/manual \
  -H "Content-Type: application/json" \
  -d '{
    "recency": 30,
    "frequency": 5,
    "monetary": 1500.00
  }'
```

Response:
```json
{
  "segment_id": 2,
  "segment_name": "Segment 2",
  "stats": {
    "Recency_mean": 45.3,
    "Recency_median": 42.0,
    "Frequency_mean": 4.8,
    "Frequency_median": 4.0,
    "Monetary_mean": 1200.50,
    "Monetary_median": 1100.00
  },
  "confidence": 0.92,
  "distance_to_center": 0.4
}
```

#### Predict Segment (Customer ID)
```bash
curl -X POST http://localhost:5001/segment/customer \
  -H "Content-Type: application/json" \
  -d '{"customer_id": 12347}'
```

Response: Same format as manual endpoint

---

## ğŸ“Š Understanding the Output

### Segment Prediction Response

```json
{
  "segment_id": 2,                    // Cluster ID (0-4)
  "segment_name": "Segment 2",        // Human-readable name
  "stats": {                          // Segment profile statistics
    "Recency_mean": 45.3,             // Avg days since purchase
    "Recency_median": 42.0,           // Median value
    "Recency_min": 1.0,               // Minimum value
    "Recency_max": 365.0,             // Maximum value
    "Frequency_mean": 4.8,            // Avg transaction count
    "Frequency_median": 4.0,
    "Frequency_min": 1.0,
    "Frequency_max": 20.0,
    "Monetary_mean": 1200.50,         // Avg spending
    "Monetary_median": 1100.00,
    "Monetary_min": 50.0,
    "Monetary_max": 5000.0
  },
  "confidence": 0.92,                 // Prediction confidence (0-1)
  "distance_to_center": 0.4           // Distance to cluster center
}
```

### RFM Features Explained

| Feature | Meaning | Direction | Interpretation |
|---------|---------|-----------|-----------------|
| **Recency** | Days since last purchase | â†“ Lower is better | Recently active customers |
| **Frequency** | Number of transactions | â†‘ Higher is better | Loyal, repeat customers |
| **Monetary** | Total spending | â†‘ Higher is better | High-value customers |

---

## ğŸ”„ Data Flow

### Training Pipeline
```
1. Load Raw Data
   â””â”€ Read Excel: Online Retail.xlsx
   
2. Data Cleaning
   â””â”€ Remove NULL CustomerID
   â””â”€ Remove Quantity â‰¤ 0
   â””â”€ Remove UnitPrice â‰¤ 0
   
3. Feature Engineering
   â””â”€ Calculate Recency (days since last purchase)
   â””â”€ Calculate Frequency (transaction count)
   â””â”€ Calculate Monetary (total spending)
   â””â”€ Save to CSV: rfm_table.csv
   
4. Feature Scaling
   â””â”€ Normalize to zero mean, unit variance
   â””â”€ Save Scaler: scaler.pkl
   
5. K-Means Training
   â””â”€ 5 clusters, random_state=42, n_init=10
   â””â”€ Save Model: kmeans_model.pkl
   
6. Profile Generation
   â””â”€ Calculate mean, median, min, max per segment
   â””â”€ Save Profiles: segment_profiles.json
```

### Prediction Pipeline (API)
```
1. Receive Request
   â””â”€ Extract RFM values (manual) or customer_id (lookup)
   
2. Scale Features
   â””â”€ Apply StandardScaler transformation
   
3. Predict Cluster
   â””â”€ K-Means predict
   
4. Calculate Confidence
   â””â”€ Inverse of distance to cluster center
   
5. Build Response
   â””â”€ Segment ID, name, stats, confidence
   â””â”€ Return JSON
```

---

## ğŸ“ File Structure

```
segmentation_agent/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ train_segmentation.py              # Model training script
â”œâ”€â”€ app.py                             # Flask API server
â”œâ”€â”€ utils.py                           # Data processing utilities
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Online Retail.xlsx            # Input data
â””â”€â”€ models/
    â”œâ”€â”€ kmeans_model.pkl              # Trained K-Means model
    â”œâ”€â”€ scaler.pkl                    # StandardScaler
    â”œâ”€â”€ segment_profiles.json         # Segment statistics
    â””â”€â”€ rfm_table.csv                 # RFM features table
```

---

## ğŸ§ª Testing

### Unit Tests (Recommended)
```bash
pytest tests/ -v
```

### Manual Testing
```bash
# Terminal 1: Start API
python app.py

# Terminal 2: Test endpoints
curl http://localhost:5001/health
curl -X POST http://localhost:5001/segment/manual \
  -H "Content-Type: application/json" \
  -d '{"recency":30,"frequency":5,"monetary":1500}'
```

---

## ğŸ” Code Structure

### `train_segmentation.py`
- **Imports**: pandas, sklearn, joblib
- **Main function**: Orchestrates entire training pipeline
- **Outputs**: 4 artifact files for API

### `app.py`
- **Flask app**: REST API server
- **Routes**:
  - `GET /health` - Health check
  - `POST /segment/manual` - Predict from manual input
  - `POST /segment/customer` - Predict from customer ID
- **Helper**: `predict_segment()` function

### `utils.py`
- **Functions**:
  - `load_raw_data()` - Read Excel file
  - `clean_data()` - Validate and filter data
  - `build_rfm_table()` - Build RFM features

---

## ğŸ› Troubleshooting

### Issue: "Model artifact not found"
**Solution:** Run `python train_segmentation.py` first

### Issue: "Customer not found"
**Response:** 404 error - Customer ID doesn't exist in training data

### Issue: "Invalid input"
**Solution:** Check JSON format and required fields

### Issue: Import errors
**Solution:** Install dependencies: `pip install -r requirements.txt`

---

## ğŸš€ Integration with Other Agents

### Output for Agent 2 (Content Retrieval)
```json
{
  "segment_id": 2,
  "segment_name": "Segment 2"
}
```

### Input from Agent 5 (Orchestrator)
```json
{
  "customer_id": 12347
}
```

---

## ğŸ“ˆ Performance Metrics

- **Model Training Time**: ~2-5 seconds
- **API Response Time**: <100ms per request
- **Max Clusters**: 5 (configurable)
- **Data Points**: ~500 customers

---

## ğŸ” Security Notes

- âœ… Input validation on all API endpoints
- âœ… Error handling for missing files/customers
- âœ… Type hints for code safety
- âš ï¸ No authentication required (add if needed)

---

## ğŸ“ Future Improvements

- [ ] Support for dynamic cluster numbers
- [ ] Model versioning and model registry
- [ ] Async API endpoints
- [ ] Database integration instead of CSV
- [ ] Model retraining scheduler
- [ ] Confidence scoring improvements
- [ ] A/B testing framework

---

## ğŸ“§ Contact & Support

**Agent Owner**: Person 1  
**Repository**: https://github.com/nermeennasim/chainreach-ai  
**Branch**: person1-feature-segmentation-api

---

## ğŸ“š References

- [RFM Analysis](https://en.wikipedia.org/wiki/RFM_(customer_value))
- [K-Means Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
- [Flask Documentation](https://flask.palletsprojects.com/)
- [Scikit-Learn Guide](https://scikit-learn.org/stable/)

---

<div align="center">

**Built with â¤ï¸ for Customer Segmentation**

*Part of the ChainReach AI Multi-Agent System*

</div>
